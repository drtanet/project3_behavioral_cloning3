{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Behavioral Cloning Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "Use the simulator to collect data of good driving behavior\n",
    "Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "Train and validate the model with a training and validation set\n",
    "Test that the model successfully drives around track one without leaving the road\n",
    "Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My project includes the following files:\n",
    "\n",
    "model.py containing the script to create and train the model\n",
    "drive.py for driving the car in autonomous mode (I did not change anything from the original)\n",
    "model.h5 containing a trained convolution neural network\n",
    "report_project3 summarizing the results\n",
    "\n",
    "successful simulation is recorded in this youtube link: (successful model as the attached model.h5 file and the attached model.py coding with those selected parameters) \n",
    "\n",
    "https://www.youtube.com/watch?v=QjB_uTHi_NM    \n",
    "\n",
    "(self-driving car level 10)\n",
    "\n",
    "I tuned my parameters and It works fine without using the fit_generator function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step (self-driving car level 0)\n",
    "\n",
    "I recorded what I've done by youtube video when I started to connect the simulation with drive.py. This step I did not train the model because I just made sure that everything was ok. Let's see how bad it is. \n",
    "\n",
    "https://www.youtube.com/watch?v=GM_W75i9PmY  \n",
    "\n",
    "\n",
    "\n",
    "### Second step (self-driving car level 1)\n",
    "\n",
    "It has improved from the level 0 by Using LeNet. The car can reach the bridge!!! (using one center camera)\n",
    "\n",
    "https://www.youtube.com/watch?v=UxUKdJ_kRmA  \n",
    "\n",
    "\n",
    "### Third step (self-driving car level 2) \n",
    "\n",
    "In the level 2, I used more data by fliping the old images from the center camera to train the model with LeNet. It has improved from the level 1. \n",
    "\n",
    "https://www.youtube.com/watch?v=WoGqgjdpQU0 \n",
    "\n",
    "\n",
    "### Fourth step (self-driving car level 3) \n",
    "\n",
    "With 3 camera (left, center, right) and with correction factor 0.2. \n",
    "\n",
    "The result does not seem good when comparing to the level 2. In the level 4, I will get back to the center camera with its augmented images only.\n",
    "\n",
    "https://www.youtube.com/watch?v=wHSYcj0QvQI \n",
    "\n",
    "\n",
    "### Fifth step (self-driving car level 4) \n",
    "\n",
    "I implemented with augmented data only from the center camera and the cropping method to cut unnecessary part out. (LeNet)\n",
    "\n",
    "https://www.youtube.com/watch?v=msGirY7IMYI \n",
    "\n",
    "\n",
    "\n",
    "### Sixth step (self-driving car level 5) \n",
    "\n",
    "I used the nvidia with one center camera. It was not working. \n",
    "\n",
    "https://www.youtube.com/watch?v=LVNEtlP3wpY&t=11s \n",
    "\n",
    "\n",
    "### Seventh step (self-driving car level 6) \n",
    "\n",
    "I used the nvidia with 3 cameras to help the car to complete the laps at the first time. However, It was not perfect. It hits the bridge. It was not desirable at all. However, it was getting better. \n",
    "\n",
    "https://www.youtube.com/watch?v=AvZOYKEUS8Y&t=26s \n",
    "\n",
    "\n",
    "### Eighth step (self-driving car level 7) \n",
    "\n",
    "I implemented with Nvidia with 3 cameras and 0.25 correction factor. It drives better than in the level 6. But it still has some problem at the bridge. It was still not desirable. I had to search the right model.\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=8YX0nSXcTVA \n",
    "\n",
    "\n",
    "### Ninth step (self-driving car level 8)\n",
    "\n",
    "\n",
    "I change the correction factor to 0.3. It works fine. However, it was outside the lane at some point. \n",
    "\n",
    "https://www.youtube.com/watch?v=dRVbOQ64iDg&t=53s\n",
    "\n",
    "\n",
    "\n",
    "### Tenth step (self-driving car level 9) \n",
    "\n",
    "I have delete some 0 steering angle images. It drives perfectly fine around the curves. However, it still had the problem when it drives on the bridge. (Nvidia with 3 cameras with correction factor 0.3)\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=O3oNzQcUdYY&t=5s \n",
    "\n",
    "\n",
    "### Eleventh step (self-driving car level 10 - succsesful model) \n",
    "\n",
    "I still use only udacity data - no more data required. (Nvidia with 3 cameras with correction factor 0.4 and epoch No. 7) \n",
    "\n",
    "https://www.youtube.com/watch?v=QjB_uTHi_NM \n",
    "\n",
    "\n",
    "model.h5 was done by model.py with those parameters that I have attached. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model Architecture and Training Strategy (self-driving car level 10 - succsesful model only)\n",
    "\n",
    "##### appropriate model architecture has been employed\n",
    "\n",
    "My model uses exactly Nvidia Net that was explained in the lecture. \n",
    "The key success is that how I filter steering 0 angle out from the whole data set as shown in model.py at line 34 and I selected the 0.4 correction factor for the left and the right images. That's it. Using this model, the can can drive like a human. \n",
    "\n",
    "\n",
    "##################### Final model architecture (Nvidia net)#####################\n",
    "Before use this architecture, please read below carefully! \n",
    "\n",
    "Data from left center right cameras. Note that images from left and right cameras are implement with 0.4 correction factor. (This is important for my simulations because I tried a lot with different factors. It was succesfully done with 0.4 and I do not need additional data. (only udacity data provided))\n",
    "\n",
    "\n",
    "However, not all of images from center cameras used. I delete some of them with 0 steering angle out! This is also an important technique because too much identical data can fool the model. \n",
    "\n",
    "\n",
    "In this first simple track with no slope, I do not use fit_generator() because the car can drive with the simple Nvidia net. It may need more data and fit_generator() for the second track (hill with many slopes), I guess. I will experiment by my own effort in the near future.\n",
    "################################################################################\n",
    "\n",
    "1st layer: input layer: lambda and cropping2d layer\n",
    "\n",
    "original image size 160x320x3 (three (rgb) channels) with normalization using lambda function and then using keras (cropping2Dlayer) for cropping images (75 pixels from the top and 25 pixels from the bottom) to delete unnecessary parts out. \n",
    "\n",
    "input: 160x320x3 (original)\n",
    "after cropping2Dlayer - ((75,20), (0,0))\n",
    "output: 65x320x3 (cropping)\n",
    "\n",
    "2nd layer: convolutional layer 5x5 kernel: (activation: relu)\n",
    "input: 65x320x3 \n",
    "output: 31x158x24 \n",
    "\n",
    "\n",
    "3rd layer: convolutional layer 5x5 kernel: (activation: relu)\n",
    "input: 31x158x24  \n",
    "output: 14x77x36 \n",
    "\n",
    "4th layer: convolutional layer 5x5 kernel: (activation: relu)\n",
    "input: 14x77x36 \n",
    "output: 5x37x48 \n",
    "\n",
    "5th layer: convolutional layer 3x3 kernel: (activation: relu)\n",
    "input: 5x37x48 \n",
    "output: 3x35x64 \n",
    "\n",
    "6th layer: convolutional layer 3x3 kernel: (activation: relu)\n",
    "input: 3x35x64 \n",
    "output: 1x33x64 \n",
    "\n",
    "7th layer: flatten \n",
    "output: 2112 neurons \n",
    "\n",
    "8th layer: fully-connected layer\n",
    "output: 100 neurons \n",
    "\n",
    "9th layer: fully-connected layer\n",
    "output: 50 neurons \n",
    "\n",
    "10th layer: fully-connected layer\n",
    "output: 10 neurons \n",
    "\n",
    "11th layer: fully-connected layer\n",
    "output: 1 neurons (vehicle control) \n",
    "#####################################################################\n",
    "\n",
    "\n",
    "##### Attempts to reduce overfitting in the model\n",
    "\n",
    "I tried Dropout as you can see in the code line 72 and 75. It did not work well. Thus, I commented it out for the successful model. I do not need it. \n",
    "\n",
    "##### Model parameter tuning\n",
    "The model used an adam optimizer, so the learning rate was not tuned manually (model.py line 87).\n",
    "\n",
    "##### Appropriate training data\n",
    "\n",
    "I only used the data from Udacity. I did not create any more data set. \n",
    "I think it is enough as you can see in the simulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Plot ########\n",
    "\n",
    "I have observed that the model that I trained again (modelnew.h5) with the same parameters as model.h5 (successful). It gives the different behavior! I do not understand why. Now I did two experiment for plots. \n",
    "\n",
    "\n",
    "In the first plot, what I did is the same as the successful model that I submitted in the first verstion. However, the car did not drive as good as before! \n",
    "\n",
    "\n",
    "<img src=\"Figure_1nodropout.png\">\n",
    "\n",
    "In the second plot, I did a small change in Nvidia. I took two dropouts in the Nvidia net as shown in Figure below: \n",
    "\n",
    "\n",
    "<img src=\"nvidia_dropout.png\">\n",
    "\n",
    "\n",
    "<img src=\"Figure_1withdropout.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.h5 is still the same as it passed. I did not overwrite it. However, I still have a question about what is happening. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
